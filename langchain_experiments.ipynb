{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: can only concatenate str (not \"bytes\") to str\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain.chains.openai_functions.openapi import get_openapi_chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# secret_key = \"sk-proj-PEDWbGTMIIIu3e49VrTGT3BlbkFJ695El2p9OX8OucEaThS7\"\n",
    "# os.environ[\"OPENAI_API_KEY\"] = secret_key\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Create the LLM instance\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# URL of the local FastAPI OpenAPI documentation\n",
    "openapi_url = \"http://127.0.0.1:8000/openapi.json\"\n",
    "\n",
    "# Fetch the OpenAPI spec to ensure it's accessible\n",
    "def fetch_openapi_spec(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise ValueError(f\"Failed to fetch OpenAPI JSON. Status code: {response.status_code}\")\n",
    "    return response.json()\n",
    "\n",
    "try:\n",
    "    openapi_spec_json = fetch_openapi_spec(openapi_url)\n",
    "\n",
    "    # Manually add the base URL to the OpenAPI spec\n",
    "    base_url = \"http://127.0.0.1:8000\"\n",
    "    if \"servers\" not in openapi_spec_json:\n",
    "        openapi_spec_json[\"servers\"] = [{\"url\": base_url}]\n",
    "    else:\n",
    "        openapi_spec_json[\"servers\"].append({\"url\": base_url})\n",
    "\n",
    "    # Save the updated OpenAPI spec to a temporary file\n",
    "    with open(\"updated_openapi.json\", \"w\") as f:\n",
    "        json.dump(openapi_spec_json, f)\n",
    "\n",
    "    # Create the chain using the updated OpenAPI spec file\n",
    "    chain = get_openapi_chain(spec=\"updated_openapi.json\", llm=llm)\n",
    "\n",
    "    # Example query to the /search_similar endpoint\n",
    "    query = \"Could you show me 4 examples of Blue Plates with Floral Patterns?\"    \n",
    "    image_path = \"/Users/deveshsurve/UNIVERSITY/INFO/7374/multi-modal-product-recommendation-chatbot/blplain.png\"\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        image = f.read()\n",
    "\n",
    "    final_query = {\n",
    "        \"query\": query,\n",
    "        \"image\": image\n",
    "    }\n",
    "    response = chain(final_query)\n",
    "    \n",
    "    print(\"Response:\")\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from langchain.chains.openai_functions.openapi import get_openapi_chain\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# import json\n",
    "# import os\n",
    "\n",
    "# secret_key = \"sk-proj-PEDWbGTMIIIu3e49VrTGT3BlbkFJ695El2p9OX8OucEaThS7\"\n",
    "# os.environ[\"OPENAI_API_KEY\"] = secret_key\n",
    "\n",
    "# # Create the LLM instance\n",
    "# llm = ChatOpenAI()\n",
    "\n",
    "# # URL of the local FastAPI OpenAPI documentation\n",
    "# openapi_url = \"http://127.0.0.1:8000/openapi.json\"\n",
    "\n",
    "# # Fetch the OpenAPI spec to ensure it's accessible\n",
    "# def fetch_openapi_spec(url):\n",
    "#     response = requests.get(url)\n",
    "#     if response.status_code != 200:\n",
    "#         raise ValueError(f\"Failed to fetch OpenAPI JSON. Status code: {response.status_code}\")\n",
    "#     return response.json()\n",
    "\n",
    "# try:\n",
    "#     openapi_spec_json = fetch_openapi_spec(openapi_url)\n",
    "\n",
    "#     # Manually add the base URL to the OpenAPI spec\n",
    "#     base_url = \"http://127.0.0.1:8000\"\n",
    "#     if \"servers\" not in openapi_spec_json:\n",
    "#         openapi_spec_json[\"servers\"] = [{\"url\": base_url}]\n",
    "#     else:\n",
    "#         openapi_spec_json[\"servers\"].append({\"url\": base_url})\n",
    "\n",
    "#     # Save the updated OpenAPI spec to a temporary file\n",
    "#     with open(\"updated_openapi.json\", \"w\") as f:\n",
    "#         json.dump(openapi_spec_json, f)\n",
    "\n",
    "#     # Create the chain using the updated OpenAPI spec file\n",
    "#     chain = get_openapi_chain(spec=\"updated_openapi.json\", llm=llm)\n",
    "\n",
    "#     # Example query to the /search_similar endpoint\n",
    "#     query = \"Could you show me 4 examples of Blue Plates with Floral Patterns?\"\n",
    "#     response = chain(query)\n",
    "\n",
    "#     print(\"Response:\")\n",
    "#     print(response)\n",
    "# except Exception as e:\n",
    "#     print(f\"Error: {e}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from langchain.chains.openai_functions.openapi import get_openapi_chain\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# import json\n",
    "\n",
    "# # Set your OpenAI API key\n",
    "# import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = secret_key\n",
    "\n",
    "# # Create the LLM instance\n",
    "# llm = ChatOpenAI()\n",
    "\n",
    "# # URL of the local FastAPI OpenAPI documentation\n",
    "# openapi_url = \"http://127.0.0.1:8000/openapi.json\"\n",
    "\n",
    "# # Fetch the OpenAPI spec to ensure it's accessible\n",
    "# def fetch_openapi_spec(url):\n",
    "#     response = requests.get(url)\n",
    "#     if response.status_code != 200:\n",
    "#         raise ValueError(f\"Failed to fetch OpenAPI JSON. Status code: {response.status_code}\")\n",
    "#     return response.json()\n",
    "\n",
    "# try:\n",
    "#     openapi_spec_json = fetch_openapi_spec(openapi_url)\n",
    "\n",
    "#     # Manually add the base URL to the OpenAPI spec\n",
    "#     base_url = \"http://127.0.0.1:8000\"\n",
    "#     if \"servers\" not in openapi_spec_json:\n",
    "#         openapi_spec_json[\"servers\"] = [{\"url\": base_url}]\n",
    "#     else:\n",
    "#         openapi_spec_json[\"servers\"].append({\"url\": base_url})\n",
    "\n",
    "#     # Save the updated OpenAPI spec to a temporary file\n",
    "#     with open(\"updated_openapi.json\", \"w\") as f:\n",
    "#         json.dump(openapi_spec_json, f)\n",
    "\n",
    "#     # Create the chain using the updated OpenAPI spec file\n",
    "#     chain = get_openapi_chain(spec=\"updated_openapi.json\", llm=llm)\n",
    "\n",
    "#     # Example query\n",
    "#     query = \"What items contain the term 'Item'?\"\n",
    "#     response = chain({\"query\": query})\n",
    "\n",
    "#     print(\"Response:\")\n",
    "#     print(response)\n",
    "# except Exception as e:\n",
    "#     print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from langchain.chains.openai_functions.openapi import get_openapi_chain\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# import json\n",
    "\n",
    "# # Set your OpenAI API key\n",
    "# import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = secret_key\n",
    "\n",
    "# # Create the LLM instance\n",
    "# llm = ChatOpenAI()\n",
    "\n",
    "# # URL of the local FastAPI OpenAPI documentation\n",
    "# openapi_url = \"http://127.0.0.1:8000/openapi.json\"\n",
    "\n",
    "# # Fetch the OpenAPI spec to ensure it's accessible\n",
    "# def fetch_openapi_spec(url):\n",
    "#     response = requests.get(url)\n",
    "#     if response.status_code != 200:\n",
    "#         raise ValueError(f\"Failed to fetch OpenAPI JSON. Status code: {response.status_code}\")\n",
    "#     return response.json()\n",
    "\n",
    "# try:\n",
    "#     openapi_spec_json = fetch_openapi_spec(openapi_url)\n",
    "#     print(\"Successfully fetched OpenAPI spec JSON:\")\n",
    "#     print(json.dumps(openapi_spec_json, indent=2))\n",
    "\n",
    "#     # Manually add the base URL to the OpenAPI spec\n",
    "#     base_url = \"http://127.0.0.1:8000\"\n",
    "#     if \"servers\" not in openapi_spec_json:\n",
    "#         openapi_spec_json[\"servers\"] = [{\"url\": base_url}]\n",
    "#     else:\n",
    "#         openapi_spec_json[\"servers\"].append({\"url\": base_url})\n",
    "\n",
    "#     # Print the updated OpenAPI spec\n",
    "#     print(\"Updated OpenAPI spec JSON with base URL:\")\n",
    "#     print(json.dumps(openapi_spec_json, indent=2))\n",
    "\n",
    "#     # Save the updated OpenAPI spec to a temporary file\n",
    "#     with open(\"updated_openapi.json\", \"w\") as f:\n",
    "#         json.dump(openapi_spec_json, f)\n",
    "\n",
    "#     # Create the chain using the updated OpenAPI spec file\n",
    "#     chain = get_openapi_chain(spec=\"updated_openapi.json\", llm=llm)\n",
    "\n",
    "#     # Example query\n",
    "#     query = \"What items contain the term 'Item'?\"\n",
    "#     response = chain({\"query\": query})\n",
    "\n",
    "#     print(\"Response:\")\n",
    "#     print(response)\n",
    "# except Exception as e:\n",
    "#     print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "client = OpenAI(api_key=\"sk-proj-PEDWbGTMIIIu3e49VrTGT3BlbkFJ695El2p9OX8OucEaThS7\")\n",
    "\n",
    "def normal_chat(prompt):\n",
    "    logger.info(f\"Normal chat detected. Responding with the same prompt.\")\n",
    "    # Later change this to a proper response\n",
    "    return prompt\n",
    "\n",
    "def extract_n_category_prompt(prompt):\n",
    "    logger.info(f\"Extracting details from prompt: {prompt}\")\n",
    "    prompt=f\"Extract the number of similar images (N) and the category from the following prompt: '{prompt}'. If not sure about the category, default to 'all'. If not sure about the number of images, default to 3. Return response in strictly json format with keys 'N' and 'category'.\",\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"{prompt}\"}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def extract_details_from_prompt(prompt):\n",
    "    logger.info(f\"Extracting details from prompt: {prompt}\")\n",
    "    try:\n",
    "        details = extract_n_category_prompt(prompt)\n",
    "        logger.info(f\"Received response from OpenAI: {details}\")\n",
    "        details_json = json.loads(details)\n",
    "        N = int(details_json.get(\"N\", 3))\n",
    "        category = details_json.get(\"category\", \"all\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        logger.error(f\"JSON decode error: {e}\")\n",
    "        N, category = 3, \"all\"\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in extracting details: {e}\")\n",
    "        N, category = 3, \"all\"\n",
    "    logger.info(f\"Extracted details - N: {N}, category: {category}\")\n",
    "    return N, category\n",
    "\n",
    "\n",
    "def __check_intent_with_gpt(user_input):\n",
    "    prompt = (\n",
    "        \"You are an AI assistant. A user is interacting with a chatbot. \"\n",
    "        \"Based on the user's input, identify if the user is engaging in normal chat, \"\n",
    "        \"asking to show similar images, or asking for complementary items.\\n\\n\"\n",
    "        \"User input: \" + user_input + \"\\n\\n\"\n",
    "        \"Identify the intent as one of the following: normal_chat, show_similar, show_complementary. \"\n",
    "        \"Respond with the intent in the following JSON format: {\\\"intent\\\": \\\"<intent>\\\"}\"\n",
    "    )\n",
    "    logger.info(f\"Extracting intent from prompt: {prompt}\")\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[  \n",
    "            {\"role\": \"user\", \"content\": f\"{prompt}\"}\n",
    "        ]\n",
    "    )\n",
    "    logger.info(f\"Received response from OpenAI: {response.choices[0].message.content}\")\n",
    "    intent = response.choices[0].message.content\n",
    "    intent_json = json.loads(intent)\n",
    "    intent = intent_json.get(\"intent\")\n",
    "    return intent\n",
    "\n",
    "\n",
    "# def determine_intent(user_input):\n",
    "#     # First layer: Keyword matching\n",
    "#     intent = __check_intent_with_keywords(user_input)\n",
    "#     logger.info(f\"Intent from keyword matching: {intent}\")\n",
    "    \n",
    "#     # Second layer: If no intent found, use GPT-3.5\n",
    "#     if intent is None:\n",
    "#         intent = __check_intent_with_gpt(user_input)\n",
    "#         intent_json = json.loads(intent)\n",
    "    \n",
    "#     return intent\n",
    "# __check_intent_with_gpt(\"Can you show similar plates?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __check_intent_with_gpt(\"Can you show similar plates?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MongoDB interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"clip-ViT-L-14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to vector search the images\n",
    "from urllib.parse import quote_plus\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "from pymongo.errors import CollectionInvalid, DuplicateKeyError\n",
    "from pymongo.operations import SearchIndexModel\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "from bson.objectid import ObjectId\n",
    "\n",
    "mongo_db_user = quote_plus(os.getenv('MONGO_DB_USER'))\n",
    "mongo_db_password = quote_plus(os.getenv('MONGO_DB_PASSWORD'))\n",
    "mongo_db_name = os.getenv('MONGO_DB_NAME')\n",
    "collection_name = os.environ.get('MONGO_COLLECTION_NAME')\n",
    "uri = f\"mongodb+srv://{mongo_db_user}:{mongo_db_password}@cluster0.eld31uu.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "print(uri)\n",
    "\n",
    "# Create a new client and connect to the server\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "db = client.get_database(mongo_db_name)\n",
    "collection = db.get_collection(collection_name)\n",
    "\n",
    "\n",
    "def encode_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    encoding = model.encode([image])\n",
    "    return encoding[0]\n",
    "\n",
    "def encode_text(text):\n",
    "    encoding = model.encode(text)\n",
    "    return encoding\n",
    "\n",
    "def image_search(emb, n = 9, collection=collection):\n",
    "    \"\"\"\n",
    "    Use MongoDB Vector Search to search for a matching image.\n",
    "    The `search_phrase` is first converted to a vector embedding using\n",
    "    the `model` loaded earlier in the Jupyter notebook. The vector is then used\n",
    "    to search MongoDB for matching images.\n",
    "    \"\"\"\n",
    "    # emb = model.encode(search_phrase)\n",
    "    cursor = collection.aggregate(\n",
    "        [\n",
    "            {\n",
    "                \"$vectorSearch\": {\n",
    "                    \"index\": \"vector_index\",\n",
    "                    \"path\": \"embedding\",\n",
    "                    \"queryVector\": emb.tolist(),\n",
    "                    \"numCandidates\": 100,\n",
    "                    \"limit\": n,\n",
    "                }\n",
    "            },\n",
    "            {\"$project\": {\"_id\": 1, \"score\": {\"$meta\": \"vectorSearchScore\"}}},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return list(cursor)\n",
    "\n",
    "def get_document_by_id(doc_id, collection=collection): \n",
    "    \"\"\"\n",
    "    Retrieve a MongoDB document by its _id and return all its fields as a dictionary.\n",
    "    \"\"\"\n",
    "    document = collection.find_one({\"_id\": doc_id})\n",
    "    return document\n",
    "\n",
    "\n",
    "def extract_fields_from_document(document, fields = [\"title\", \"categories\", \"price\", \"thumbnailImages\", \"condition\"]):\n",
    "    \"\"\"\n",
    "    Extract the fields 'title', 'description', 'category', 'image_url' from the MongoDB document.\n",
    "    \"\"\"\n",
    "    return {field: document.get(field) for field in fields}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode_image(\"images/v1|335356534874|0_0.jpg\")\n",
    "# /Users/deveshsurve/UNIVERSITY/INFO/7374/multi-modal-product-recommendation-chatbot/bplt.jpeg\n",
    "emb_image = encode_image(\"/Users/deveshsurve/UNIVERSITY/INFO/7374/multi-modal-product-recommendation-chatbot/blplain.png\")\n",
    "# emb_text = encode_text(\"Can you show me white plates?\")\n",
    "search_results = image_search(emb_image, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_document_by_id(collection, search_results[0][\"_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(extract_fields_from_document(get_document_by_id(collection, search_results[0][\"_id\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gpt Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_gpt_response(prompt):\n",
    "    logger.info(f\"Generating response for prompt: {prompt}\")\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"{prompt}\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def gpt_response_similar(user_prompt, metadata):\n",
    "    similar_prompt = f'''You are a chatbot assistant. A user is interacting with you and \n",
    "                        has asked you to show similar products using this prompt {user_prompt}. \n",
    "                        Following is the details of the recomended products {metadata}. \n",
    "                        Use this information and generate a chat reposnse'''\n",
    "\n",
    "\n",
    "    return my_gpt_response(similar_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search with only text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Can you show me 5 floral plates?\"\n",
    "# intent = __check_intent_with_gpt(prompt)\n",
    "intent = \"show_similar\"\n",
    "if intent == \"normal_chat\":\n",
    "    response = normal_chat(prompt)\n",
    "elif intent == \"show_similar\":\n",
    "    N, category = extract_details_from_prompt(prompt)\n",
    "    search_results = image_search(encode_text(prompt), N)\n",
    "    metadata = [str(extract_fields_from_document(get_document_by_id(collection, search_results[i][\"_id\"]))) for i in range(N)]\n",
    "    # response = gpt_response_similar(prompt, metadata)\n",
    "\n",
    "metadata    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def driver_fn(prompt, image=None):\n",
    "    intent = determine_intent(prompt)\n",
    "    if intent == \"normal_chat\":\n",
    "        return normal_chat(prompt)\n",
    "    elif intent == \"show_similar\":\n",
    "        if image:\n",
    "            N, category = extract_details_from_prompt(prompt)\n",
    "            similar_images = get_similar_images(image, n=N, category=category)\n",
    "            return similar_images\n",
    "        else:\n",
    "            return \"I don't have an image to show similar images for. Please provide an image URL.\"\n",
    "    elif intent == \"show_complementary\":\n",
    "        if image:\n",
    "            N, category = extract_details_from_prompt(prompt)\n",
    "            complementary_images = get_complementary_images(prompt, image, n=N, category=category)\n",
    "            return complementary_images\n",
    "        else:\n",
    "            return \"I don't have an image to show complementary images for. Please provide an image URL.\"\n",
    "    else:\n",
    "        return normal_chat(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
